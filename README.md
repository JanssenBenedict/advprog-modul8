- Name: Janssen Benedict
- Class: Pemrograman Lanjut A
- NPM: 2306152102

# Module 08: High Level Networking - Reflection

### 1. What are the key differences between unary, server streaming, and bi-directional streaming RPC (Remote Procedure Call) methods, and in what scenarios would each be most suitable?
The key differences between the unary, server streaming, and bi-directional streaming RPC methods lie within how each RPC method handles client-server interactions, such as:
- The Unary RPC method handles client-server interactions by having the client send a single request and receive a single response from the server.
- The Server Streaming RPC method handles client-server interactions by having the client send a single request and receive multiple responses streamed from the server itself.
- The Bi-directional Streaming RPC method handles client-server interactions by having both the client and the server exchange streams of messages independently.
The scenarios in which each RPC method would be most suitable are:
- The Unary RPC method is most suitable in scenarios where simple one-time operations need to be executed (a single request needs to be made and a single response is needed in return), such as user authentication or other simple CRUD operations.
- The Server Streaming RPC method is most suitable in scenarios where the server needs to send a continuous stream of data, especially when dealing with data in large sets, such as sending constant updates or logging entries.
- The Bi-directional Streaming RPC method is most suitable in scenarios involving interactive communication at real-time where both the client and the server can send and receive messages simultaneously, such as live chat functions in applications.

### 2. What are the potential security considerations involved in implementing a gRPC service in Rust, particularly regarding authentication, authorization, and data encryption?
- The potential security considerations involved in implementing a gRPC service in Rust regarding authentication consist of secure communication implementation between the client and the server. In order to achieve this, mTLS (Mutual Transport Layer Security) can be used to ensure that both the client and the server authenticate one another using digital certificates to verify their identities. This method is much more useful when compared to the standard TLS, where only one side presents the digital certificate and not both. In addition to that, token-based authentication mechanisms, like JWT (JSON Web Tokens), can be implemented to achieve stronger access control whenever requests are made to the gRPC service.
- The potential security considerations involved in implementing a gRPC service in Rust regarding authorization consist of making sure that properly authenticated users have the appropriate permissions to perform the specific actions needed only. To enforce this, RBAC (Role-Based Access Control) can be utilized to make sure different users have different privileges based on their roles. This can be implemented with interceptors to verify claims within tokens (like JWT) before users can receive access to certain functionalities.
- The potential security considerations involved in implementing a gRPC service in Rust regarding data encryption consist of proper sensitive data protection in transit and at rest. To protect data transferred over a network, the data must be encrypted in transit, this can be done by utilizing TLS encryption for communications between the client and the server. To protect sensitive data stored in the system, the data must be encrypted at rest, this can be done by utilizing specific encryption mechanisms (like AES-256) before storing the data or using specific extensions to manage encrypted data stored in databases (like pgcrypto for PostgreSQL databases). Key Management System tools could also be utilized to safely store important encryption keys (like AWS KMS, Google Cloud KMS, or HashiCorp Vault).

### 3. What are the potential challenges or issues that may arise when handling bidirectional streaming in Rust gRPC, especially in scenarios like chat applications?
When handling bidirectional streaming in Rust gRPC, especially for scenarios such as chat applications, there are a few challenges that might arise, such as:
- Proper concurrency management: Bi-directional streaming in Rust gRPC involves both the client and the server exchanging multiple messages independently through a stream. However, due to Rust's asynchronous runtime, improper management of the tasks could lead to dangerous situations, such as deadlocks or race conditions. If proper handling of asynchronous operations isn't done, it could lead to cases where the asynchronous tasks meant to manage the chat system end up blocking one another.
- Flow control and backpressure: In a chat application, there might be cases where the sender ends up transmitting messages far too quickly, to the point where the receiver is overwhelmed and couldn't process them all in time. By default, gRPC utilizes HTTP/2, which includes built-in flow control mechanisms. However, at the application-level, backpressure mechanisms also need to be implemented. If not, it could lead to other issues, such as buffer overflows, severely increased memory usage, or even messages being dropped due to the large message buildup that might occur.
- Error handling and cancellation: Bi-directional streaming also involves possible errors occurring at both sides of the communication process. These errors consists of network failures, message processing issues, or other possible errors. These exceptions must be handled properly in order to prevent resource leaks, connection hanging, or system crashes. Proper error handling and cancellation could be done by sending error messages without disrupting the flow of communication, utilizing cancellation tokens to shut down communications gracefully, or cleaning up any held resources when a stream terminates.

### 4. What are the advantages and disadvantages of using the tokio_stream::wrappers::ReceiverStream for streaming responses in Rust gRPC services?
- Advantages: One of the advantages of using the tokio_stream::wrappers::ReceiverStream for streaming responses in Rust gRPC services is that the ReceiverStream allows easy integration of Rustâ€™s asynchronous channels (Tokio) with gRPC streams, allowing for simplified asynchronous communications. Another advantage is that it's concurrency friendly, as the sender can be cloned and shared across many tasks, allowing them all to push messages into the same stream independently. Additionally, it handles backpressure effectively by allowing the sender to properly await streaming responses when the receiver is overwhelmed. It also helps in cleaning up held resources when a stream terminates or a channel is closed, avoiding any possible resource leaks.
- Disadvantages: One of the disadvantages of using the tokio_stream::wrappers::ReceiverStream for streaming responses in Rust gRPC services is that stream control is fairly limited due to ReceiverStream simply being a thin wrapper around the Tokio mpsc::Receiver, which doesn't have the mechanisms needed for more advanced and complex streaming scenarios. Other than that, because ReceiverStream is just a thin wrapper, it doesn't provide any error handling mechanisms, thus resulting in harder error handling and custom error signaling implementations are necessary. And finally, for more simple use cases, like sending a known and finite collection of items that could be produced synchronously, setting up an mpsc channel and wrapping it in a ReceiverStream actually introduces unnecessary complexity.

### 5. In what ways could the Rust gRPC code be structured to facilitate code reuse and modularity, promoting maintainability and extensibility over time?
- Split the services present into their own separate Rust modules to enhance modularity. For example, we can create directories like src/client/ and src/server/. Within the client/ module, there could be files such as payment_client.rs, transaction_client.rs, and chat_client.rs with each of them encapsulating the logic for interacting with a specific gRPC service. Within the server/ module, there could be files such as payment_service.rs, transaction_service.rs, and chat_service.rs with each of them containing the implementation of the service trait corresponding to their file names.
- Allow for custom error handling to separate business logic errors from the transport-level errors. This can be done by defining a new common error type with different error cases and then implementing conversion for each of those error cases into the appropriate gRPC Status. After that, we use it in our service code by returning these errors on certain cases in the business logic. This allows for cleaner and more maintainable service code.
- Organize the creation of unit and integration tests for each module and place them in their own dedicated tests/ directory.
- Implement trait-based abstraction for the business logic to separate the business logic from the gRPC protocol details, enhancing reusability and testability. This can be done by defining a trait that contains the core functionality and then creating the concrete implementation of the trait. Afterwards, we can call the trait method from the handler in the gRPC service implementation.

### 6. In the MyPaymentService implementation, what additional steps might be necessary to handle more complex payment processing logic?
- Proper input validation: We need to validate the PaymentRequest field data. In order to do this, we could check to see if they are present and not empty or null, make sure that they are in the valid format (amount is integer above 0 and user_id is valid), and utilize other libraries or custom logic to reject possible malicious input.
- Proper authentication and authorization: We need to validate the identity of the user through the use of tokens (like JWT) and ensure that the user is authorized or permitted to perform the payment operations. 
- Payment Gateway Integration: We could integrate the payment process with actual payment processors commonly used in real life, like PayPal, GoPay, DANA, or any other services. We should also handle their responses, like the messages received if the external payment process succeeds or fails.
- Proper Error Handling: We need to handle the issues that could arise from the payment processing logic going wrong by returning meaningful gRPC Status errors.
- Logging and Monitoring: We could keep track of all the incoming requests, external gateway interactions, and even the payment processing failures by utilizing structured logging.

### 7. What impact does the adoption of gRPC as a communication protocol have on the overall architecture and design of distributed systems, particularly in terms of interoperability with other technologies and platforms?
Adopting gRPC as a communication protocol affects the architecture and design of the distributed system significantly. One of the main differences is that the system is now more focused on a contract-first design utilizing Protocol Buffers or .proto files to enhance consistency and reduce ambiguity across the services. Other than that, gRPC adoption allows HTTP/2 multiplexing and binary serialization, which can help reduce CPU usage and latency substantially in comparison to HTTP/1 and REST. gRPC also provides built-in support for load balancing, retries, deadlines, and others, making it perfect for integration with modern service meshes. However, this also results in tight coupling to HTTP/2 and Protocol Buffers. If these services need to be exposed to clients based on HTTP/1.1 (web browsers), gRPC gateways or proxies need to be utilized.

### 8. What are the advantages and disadvantages of using HTTP/2, the underlying protocol for gRPC, compared to HTTP/1.1 or HTTP/1.1 with WebSocket for REST APIs?
- Advantages: 
1. Multiplexing: Multiple requests and responses can be exchanged in parallel over a single connection without any blocking.
2. Server push: HTTP/2 allows for active resource pushing, this results in reduced latency for any resource fetching needed to be done.
3. Header compression: HTTP/2 reduces the size of HTTP headers sent with each request and response, allowing for increased performance, especially when the same headers need to be sent over repeatedly.
4. Binary framing feature: HTTP/2 allows for communication to be broken down into binary-encoded frames. This is far more efficient than HTTP/1.1, which uses plain text messages with headers and bodies formatted as strings.
- Disadvantages:
1. Limited support for gRPC on browser environments: Typically, native browser clients do not support gRPC over HTTP/2 well.
2. Complex debugging: The more advanced protocols presented would result in harder debugging, unless some gRPC-specific tools are utilized.
3. Infrastructure compatibility: Many existing network middleboxes, like proxies, firewalls, and others were designed for HTTP/1.1 and many not be able to handle HTTP/2's multiplexing, header compression, or binary framing.

### 9. How does the request-response model of REST APIs contrast with the bidirectional streaming capabilities of gRPC in terms of real-time communication and responsiveness?
The request-response model of REST APIs is based on synchronous and stateless interactions where each request from a client corresponds to a response from the server. This model is simpler and more intuitive, appropriate for more simple CRUD operations. However, REST APIs do have limitations when it comes to real-time updates and streams, resulting in latency, increased overhead, and reduced performance in situations where constant exchanges of data need to be done.
The bidirectional streaming capabilities of gRPC, on the other hand, offer a much more advantageous solution for increased performance in real-time applications. It allows the client and the server to exchange streams of messages simultaneously over a single HTTP/2 connection. This helps reduce latency and overhead, making it the more suitable option for interactive applications with operations that need to be executed in real-time, such as live chat applications and other variations.

### 10. What are the implications of the schema-based approach of gRPC, using Protocol Buffers, compared to the more flexible, schema-less nature of JSON in REST API payloads?
The schema-based approach of gRPC using Protocol Buffers offers strong type safety, effective binary serialization, and strict contract enforcement between services, allowing for better performance and data transmission speed. Protocol Buffer schemas must be defined in .proto files, which describe the structure of the data exchanged. Once the .proto file is written, code can automatically be generated in many different programming languages to produce the boilerplate classes and methods needed. This helps reduce the risk of miscommunication between the services and saves the developer lots of time. This structure also helps detect issues at compile time, rather than runtime.
The schema-less nature of JSON in REST API payloads is considered more readable and flexible, this makes it easier to work with during development. However, this flexibility aspect could also lead to a lot of data structure inconsistencies, runtime errors, and version drifts if not handled properly. Other than that, JSON is also much more expansive or verbose when compared to Protocol Buffers, which could result in higher latency and larger amounts of data that need to be transmitted.